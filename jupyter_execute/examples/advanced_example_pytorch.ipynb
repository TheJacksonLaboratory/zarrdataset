{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a9f6b1",
   "metadata": {},
   "source": [
    "# Integration of ZarrDataset with PyTorch's DataLoader (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarrdataset as zds\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, ChainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6086aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are images from the Image Data Resource (IDR) \n",
    "# https://idr.openmicroscopy.org/ that are publicly available and were \n",
    "# converted to the OME-NGFF (Zarr) format by the OME group. More examples\n",
    "# can be found at Public OME-Zarr data (Nov. 2020)\n",
    "# https://www.openmicroscopy.org/2020/11/04/zarr-data.html\n",
    "\n",
    "filenames = [\n",
    "    \"https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.1/6001240.zarr\",\n",
    "    \"https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.1/6001241.zarr\",\n",
    "    \"https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.1/6001242.zarr\",\n",
    "    \"https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.1/6001243.zarr\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5fa55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(478963)\n",
    "torch.manual_seed(478964)\n",
    "random.seed(478965)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ba888",
   "metadata": {},
   "source": [
    "### Extracting patches of size 128x128x32 voxels from a three-dimensional image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422d652a",
   "metadata": {},
   "source": [
    "Sample the image randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02745e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = dict(Z=32, Y=128, X=128)\n",
    "patch_sampler = zds.PatchSampler(patch_size=patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6e137d",
   "metadata": {},
   "source": [
    "Transform the input data from uint16 to float16 with a torchvision pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3769ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "img_preprocessing = torchvision.transforms.Compose([\n",
    "    zds.ToDtype(dtype=np.float16)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5081f2",
   "metadata": {},
   "source": [
    "Pass the pre-processing function to ZarrDataset to be used when generating the samples.\n",
    "\n",
    "Also, enable return of each patch positions, and the worker ID that generated each patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f916a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_datasets = [\n",
    "  zds.ZarrDataset(\n",
    "    [\n",
    "      zds.ImagesDatasetSpecs(\n",
    "        filenames=fn,\n",
    "        data_group=\"0\",\n",
    "        source_axes=\"TCZYX\",\n",
    "        transform=img_preprocessing,\n",
    "      )\n",
    "    ],\n",
    "    patch_sampler=patch_sampler,\n",
    "    shuffle=True,\n",
    "    return_positions=True,\n",
    "    return_worker_id=True\n",
    "  )\n",
    "  for fn in filenames\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c085f4a6",
   "metadata": {},
   "source": [
    "### Create a ChainDataset from a set of ZarrDatasets that can be put together a single large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_chain_dataset = ChainDataset(my_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46886013",
   "metadata": {},
   "source": [
    "Make sure the chained_zarrdataset_worker_init_fn function is passed to the DataLoader, so the workers can initialize the dataset correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa42ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataloader = DataLoader(my_chain_dataset,\n",
    "                           num_workers=4,\n",
    "                           worker_init_fn=zds.chained_zarrdataset_worker_init_fn,\n",
    "                           batch_size=2\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aee72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "positions = []\n",
    "wids = []\n",
    "for i, (wid, pos, sample) in enumerate(my_dataloader):\n",
    "    wids += [w for w in wid]\n",
    "    positions += [p for p in pos]\n",
    "    samples += [s for s in sample]    \n",
    "\n",
    "    print(f\"Sample {i+1} with size {sample.shape} extracted by worker {wid}.\")\n",
    "\n",
    "    if i >= 4:\n",
    "        # Take five batches for illustration purposes\n",
    "        break\n",
    "\n",
    "samples = torch.cat(samples, dim=0)\n",
    "\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c774a8",
   "metadata": {},
   "source": [
    "### Generate a grid with the sampled patches using `torchvision` utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b997be",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_grid = torchvision.utils.make_grid(samples[:, :, 16, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de13983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(samples_grid[0], cmap=\"gray\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4915d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(samples_grid[1], cmap=\"gray\")\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 120
  },
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.15.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   14,
   18,
   25,
   40,
   48,
   52,
   56,
   59,
   63,
   69,
   75,
   93,
   97,
   99,
   103,
   111,
   129,
   133,
   137,
   144
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}